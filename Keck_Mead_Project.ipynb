{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d392a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"Q:/Dillon/Documents/School/CS_455/Project/CS455_Project/happy-whale-and-dolphin/\"\n",
    "labels_train = []\n",
    "labels_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766dd588",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(pd.read_csv(work_dir+ 'train.csv', header= 0))\n",
    "#print(train_data[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(X_train, X_test, labels_train, w, max_photo):\n",
    "    for set in [\"train\", \"test\"]:\n",
    "        count = 0\n",
    "        image_dir = work_dir+ set+ \"_images\"\n",
    "        files = glob.glob(image_dir+ \"/*.jpg\")\n",
    "        for f in files[:max_photo]:\n",
    "            count +=1\n",
    "            print(set, \" file \", count, \" loading.\")\n",
    "            img = Image.open(f)\n",
    "            img = ImageOps.grayscale(img)\n",
    "            img = img.resize((w,w))\n",
    "            data = np.array(img)\n",
    "            if set == \"train\":\n",
    "                X_train.append(data)\n",
    "                labels_train.append(train_data[train_data[:,0] == f,2])\n",
    "            elif set == \"test\":\n",
    "                X_test.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_traindata(X_train, X_test, labels_train, labels_test, max_photo, w = 64, split= 0.7):\n",
    "    count = 0\n",
    "    image_dir = work_dir+ \"train_images\"\n",
    "    files = glob.glob(image_dir+ \"/*.jpg\")\n",
    "    for f in files[:max_photo]:\n",
    "        img = Image.open(f)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img = img.resize((w,w))\n",
    "        data = np.array(img)\n",
    "        if count < max_photo*split:\n",
    "            print(\"Train file \", count+1, \" loading.\")\n",
    "            X_train.append(data)\n",
    "            labels_train.append(train_data[train_data[:,0] == f, 2])\n",
    "        elif count >= max_photo*split:\n",
    "            print(\"Test file \", count+1, \" loading.\")\n",
    "            X_test.append(data)\n",
    "            labels_test.append(train_data[train_data[:,0] == f, 2])\n",
    "        count +=1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203989b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_64 = []\n",
    "X_test_64 = []\n",
    "load_split_traindata(X_train_64, X_test_64, labels_train, labels_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb778af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_128 = []\n",
    "X_test_128 = []\n",
    "load_split_traindata(X_train_128, X_test_128, labels_train, labels_test, 100, w= 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786fc294",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.asarray(labels_train)\n",
    "labels_test = np.asarray(labels_test)\n",
    "print(X_train_64[0])\n",
    "#X_train_64 = np.asarray(X_train_64)\n",
    "print(labels_train.shape, labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43569ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train_64[69])\n",
    "plt.title(labels_train[69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train_128[69])\n",
    "plt.title(labels_train[69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_100 = RandomForestClassifier(n_estimators = 100, random_state= 42)\n",
    "rf64_100 = rf_100.fit(X_train_64, labels_train)\n",
    "rf128_100 = rf_100.fit(X_train_128, labels_train)\n",
    "rf64_100_predict = rf64_100.predict(X_test_64)\n",
    "rf128_100_predict = rf128_100.predict(X_test_128)\n",
    "print(\"64 pixel random forest accuracy: \", rf_100.score(X_test_64, rf64_100_predict))\n",
    "print(\"128 pixel random forest accuracy: \", rf_100.score(X_test_128, rf128_100_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152af54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_100 = KNeighborsClassifier()\n",
    "knn64_100 = knn_100.fit(X_train_64, labels_train)\n",
    "knn128_100 = knn_100.fit(X_train_128, labels_train)\n",
    "knn64_100_predict = knn64_100.predict(X_test_64)\n",
    "knn128_100_predict = knn128_100.predict(X_test_128)\n",
    "print(\"64 pixel knn accuracy: \", knn_100.score(X_test_64, knn64_100_predict))\n",
    "print(\"128 pixel knn accuracy: \", knn_100.score(X_test_64, knn64_100_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b2b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
